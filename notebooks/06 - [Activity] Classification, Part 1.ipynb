{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice applying what we've learned to a house price dataset for Ames, Iowa. We'll try to predict whether the house price is \"high\" or \"low\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
      "0      1  526301100           20        RL         141.0     31770   Pave   \n",
      "1      2  526350040           20        RH          80.0     11622   Pave   \n",
      "2      3  526351010           20        RL          81.0     14267   Pave   \n",
      "3      4  526353030           20        RL          93.0     11160   Pave   \n",
      "4      5  527105010           60        RL          74.0     13830   Pave   \n",
      "\n",
      "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
      "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
      "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
      "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
      "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
      "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
      "\n",
      "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
      "0        0       5    2010       WD           Normal     215000  \n",
      "1        0       6    2010       WD           Normal     105000  \n",
      "2    12500       6    2010       WD           Normal     172000  \n",
      "3        0       4    2010       WD           Normal     244000  \n",
      "4        0       3    2010       WD           Normal     189900  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop or fill missing values. Consider how to handle the following columns, which have many missing values: `Alley`, `Fence`, `Fireplace Qu`, `Misc Feature`, `Pool QC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Separate the features and the class. Here, our class is the last column `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transform the features to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bin the SalePrice into two outcomes, 'high' or 'low'. Make them roughly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Encode the binned SalePrice into integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Split the dataset into 80% training data and 20% testing data. Each row should consist of the features, `X`, and the binned sales price, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Fit three models: a 1-nearest neighbors classifier, a 10-nearest neighbors classifier, and a 100-nearest neighbors classifier. Fit them all on the training data. Use all of the feature data to predict the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compare the accuracy of the _k_-nearest neighbors classifiers on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Now fit a perceptron classifier and logistic regression classifier on the training data. Compare the accuray of the perceptron, logistic regression, and the KNN classifiers. Which performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
